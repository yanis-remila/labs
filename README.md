#  Architecture Big Data pour Gestion de Freelances


---

## RÃ‰CAPITULATIF DES 5 LIVRABLES

### âœ… 1. Diagramme de Composants

**Architecture logique en 5 couches** :

1. **Couche Ingestion**
    - File Loader JSON/CSV
    - Kafka Producer

2. **Couche Streaming**
    - **Topic: Profils** (2 partitions)
    - **Topic: Factures** (2 partitions)
    - Kafka Consumer

3. **Couche Traitement**
    - Spark Master (orchestration)
    - Worker 1 (ID 1-500)
    - Worker 2 (ID 501-1000)
    - **T1: Nettoyage** (doublons + validation)
    - **T2: Calculs Financiers** (CA + revenus)
    - **T3: AgrÃ©gations** (compÃ©tences + taux)

4. **Couche Stockage**
    - PostgreSQL (PGsql)
    - 3 tables : Freelances, Factures, Indicateurs

5. **Couche Visualisation**
    - Dashboard Financier
    - Dashboard Ressources
    - Suivi Temps RÃ©el

```mermaid
graph TB
    subgraph "ğŸ“¦ COUCHE INGESTION"
        C1["ğŸ“„ File Loader JSON/CSV<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: DataIngestion<br/>RÃ´le: Lecture fichiers sources<br/>Input: JSON (Profils), CSV (Factures)"]

        C2["ğŸ”Œ Kafka Producer<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: MessageBroker<br/>RÃ´le: Publication vers topics<br/>Output: 2 topics distincts"]
    end

    subgraph "ğŸš€ COUCHE STREAMING"
        C3A["ğŸ“¨ Topic: Profils<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: EventStreaming<br/>RÃ´le: Flux nouveaux freelances<br/>Partitions: 2"]

        C3B["ğŸ“¨ Topic: Factures<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: EventStreaming<br/>RÃ´le: Flux paiements<br/>Partitions: 2"]

        C4["ğŸ‘‚ Kafka Consumer<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: StreamConsumer<br/>RÃ´le: Consommation messages<br/>Tech: Spark Streaming"]
    end

    subgraph "âš¡ COUCHE TRAITEMENT"
        C5["ğŸ¯ Spark Master<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: Orchestrator<br/>RÃ´le: Coordination + Distribution<br/>API: Cluster Manager"]

        C6A["âš™ï¸ Worker 1<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: DataProcessor<br/>RÃ´le: Traitement ID 1-500<br/>Partition: 0"]

        C6B["âš™ï¸ Worker 2<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: DataProcessor<br/>RÃ´le: Traitement ID 501-1000<br/>Partition: 1"]

        subgraph Transform["ğŸ’¾ Transformations Spark SQL"]
            C7A["ğŸ§¹ T1: Nettoyage<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Suppression doublons<br/>Validation donnÃ©es"]

            C7B["ğŸ’° T2: Calculs Financiers<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>CA par freelance<br/>Revenus mensuels"]

            C7C["ğŸ“Š T3: AgrÃ©gations<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Top compÃ©tences<br/>Taux d'occupation"]
        end
    end

    subgraph "ğŸ—„ï¸ COUCHE STOCKAGE"
        C8["ğŸ“Š PostgreSQL (PGsql)<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: DataWarehouse<br/>Tables:<br/>â€¢ Freelances (profils + compÃ©tences)<br/>â€¢ Factures (historique paiements)<br/>â€¢ Indicateurs (KPIs + stats)"]
    end

    subgraph "ğŸ“Š COUCHE VISUALISATION"
        C10A["ğŸ’° Dashboard Financier<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: PowerBI-Finance<br/>â€¢ Top 10 freelances par CA<br/>â€¢ Ã‰volution revenus mensuels"]

        C10B["ğŸ‘¥ Dashboard Ressources<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: PowerBI-RH<br/>â€¢ CompÃ©tences disponibles<br/>â€¢ Taux occupation: 78%"]

        C10C["âš¡ Suivi Temps RÃ©el<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: PowerBI-Live<br/>â€¢ Missions en cours<br/>â€¢ Nouvelles factures"]
    end

    subgraph "ğŸ”§ COUCHE SUPPORT"
        C12["ğŸ“ Logger<br/>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€<br/>Composant: Monitoring<br/>RÃ´le: Logs & Alertes"]
    end

    C1 -->|"JSON + CSV"| C2
    C2 -->|"Produit profils"| C3A
    C2 -->|"Produit factures"| C3B
    C3A -->|"Consomme"| C4
    C3B -->|"Consomme"| C4
    C4 -->|"Envoie flux"| C5
    C5 -->|"Distribue 1-500"| C6A
    C5 -->|"Distribue 501-1000"| C6B
    C6A -->|"Process"| C7A
    C6B -->|"Process"| C7A
    C7A -->|"DonnÃ©es nettoyÃ©es"| C7B
    C7B -->|"Calculs terminÃ©s"| C7C
    C7C -->|"Ã‰crit"| C8
    C8 -->|"Connexion"| C10A
    C8 -->|"Connexion"| C10B
    C8 -->|"Connexion"| C10C
    C5 -.->|"Interroge localisation"| C6A
    C5 -.->|"Interroge localisation"| C6B
    C7A -.->|"Log"| C12
    C7B -.->|"Log"| C12
    C7C -.->|"Log"| C12

    style C1 fill:#e3f2fd
    style C2 fill:#e3f2fd
    style C3A fill:#fff9c4
    style C3B fill:#fff9c4
    style C4 fill:#fff9c4
    style C5 fill:#ef5350,color:#fff
    style C6A fill:#ffcdd2
    style C6B fill:#ffcdd2
    style C7A fill:#fff176
    style C7B fill:#fff176
    style C7C fill:#fff176
    style C8 fill:#c8e6c9
    style C10A fill:#b39ddb
    style C10B fill:#b39ddb
    style C10C fill:#b39ddb
    style C12 fill:#e0e0e0
```



---

### âœ… 2. Diagramme de DÃ©ploiement
**Fichier** : `diagramme-deploiement-v2.mermaid`

**Infrastructure Cloud en 3 zones** :

**Zone 1 : Ingestion & Streaming**
- Serveur Ingestion : 8 GB RAM, 4 cores
- Kafka Broker 01 : 16 GB RAM, 8 cores
    - Topic Profils (2 partitions)
    - Topic Factures (2 partitions)
- Kafka Broker 02 : RÃ©plication

**Zone 2 : Traitement DistribuÃ©**
- Spark Master : 32 GB RAM, 16 cores
- Spark Worker 01 : 16 GB RAM (ID 1-500)
- Spark Worker 02 : 16 GB RAM (ID 501-1000)

**Zone Stockage**
- PostgreSQL : 64 GB RAM, 2 TB SSD
- Object Storage : S3/Blob 10 TB

**Protocoles** :
- SFTP (Port 22) : Upload fichiers
- Kafka (Port 9092) : Streaming
- JDBC (Port 5432) : BDD
- HTTPS : Power BI

---

### âœ… 3. Indicateurs BI et Machine Learning
**Fichier** : `indicateurs-bi-ml-v2.md`

#### ğŸ“Š 3 Dashboards Power BI

**1. Dashboard Financier**
- Top 10 freelances par CA
- Ã‰volution revenus mensuels (line chart)
- KPIs : CA total, TJM moyen
- RequÃªtes SQL : CA par freelance, Revenus mensuels

**2. Dashboard Ressources**
- CompÃ©tences disponibles (pie chart)
- Taux d'occupation : 78% (gauge)
- Freelances disponibles vs en mission
- Top compÃ©tences demandÃ©es

**3. Suivi Temps RÃ©el**
- Missions en cours (compteur live)
- Nouvelles factures du jour
- Refresh : 30 secondes
- Alertes factures en retard

#### ğŸ¤– 3 ModÃ¨les ML

**1. PrÃ©diction CA Mensuel**
- Type : Time Series (ARIMA/Prophet)
- MAPE cible : < 15%
- PrÃ©diction : 3 mois

**2. Matching Freelance-CompÃ©tence**
- Type : Content-Based Filtering
- Precision@5 : > 70%

**3. DÃ©tection Anomalies Factures**
- Type : Isolation Forest
- Taux faux positifs : < 5%

#### ğŸ’¾ 3 Transformations Spark SQL

**T1: Nettoyage**
```sql
-- Suppression doublons
-- Validation formats (email, dates, montants)
-- Normalisation donnÃ©es
```

**T2: Calculs Financiers**
```sql
-- CA par freelance
-- Revenus mensuels
-- TJM moyen par compÃ©tence
```

**T3: AgrÃ©gations**
```sql
-- Top compÃ©tences demandÃ©es
-- Taux d'occupation global
-- KPIs consolidÃ©s
```

---

### âœ… 4. Backlog Teams
**Fichier** : `backlog-teams-v2.md`

**7 Epics, 14 User Stories**

**EPIC 1 : Infrastructure Kafka**
- US-1.1 : Configuration 2 Topics (8 pts)
- US-1.2 : Script ingestion JSON/CSV (5 pts)

**EPIC 2 : Cluster Spark**
- US-2.1 : DÃ©ploiement Spark (8 pts)
- US-2.2 : Consumer Kafka â†’ Spark (13 pts)

**EPIC 3 : Transformations SQL**
- US-3.1 : T1 Nettoyage (5 pts)
- US-3.2 : T2 Calculs Financiers (8 pts)
- US-3.3 : T3 AgrÃ©gations (8 pts)

**EPIC 4 : Data Warehouse**
- US-4.1 : SchÃ©ma PostgreSQL (5 pts)
- US-4.2 : Pipeline ETL (8 pts)

**EPIC 5 : Dashboards Power BI**
- US-5.1 : Dashboard Financier (5 pts)
- US-5.2 : Dashboard Ressources (5 pts)
- US-5.3 : Suivi Temps RÃ©el (8 pts)

**EPIC 6 : Machine Learning**
- US-6.1 : PrÃ©diction CA (13 pts)
- US-6.2 : DÃ©tection anomalies (13 pts)

**Planning : 7 Sprints - 14 semaines**

| Sprint | Stories | Points | Objectif |
|--------|---------|--------|----------|
| Sprint 1 | 1.1, 1.2, 2.1 | 21 | Infra Kafka + Spark |
| Sprint 2 | 2.2, 3.1, 3.2, 4.1 | 31 | Transformations + DB |
| Sprint 3 | 3.3, 4.2, 5.1 | 21 | T3 + Dashboard Financier |
| Sprint 4 | 5.2 | 5 | Dashboard Ressources |
| Sprint 5 | 5.3 | 8 | Suivi Temps RÃ©el |
| Sprint 6 | 6.1 | 13 | ML PrÃ©diction |
| Sprint 7 | 6.2 | 13 | ML Anomalies |

**Total : 125 points**

---

### âœ… 5. Fichier Excel Git-Backlog
**Fichier** : `suivi_git_backlog_v2.xlsx`

**3 Feuilles Excel** :

#### Feuille 1 : Suivi Git-Backlog
- **14 User Stories** avec :
    - Epic, ID, Titre, PrioritÃ©, Points
    - Sprint, Assignation, Statut
    - Liens Git (branches, commits)
    - Liens Backlog (Azure DevOps)
    - Dates (dÃ©but, fin)
    - Notes dÃ©taillÃ©es

**Mise en forme** :
- ğŸŸ¢ TerminÃ© (fond vert)
- ğŸŸ¡ En cours (fond jaune)
- ğŸ”´ Ã€ faire (fond rouge)
- PrioritÃ©s colorÃ©es (Haute=rouge, Moyenne=orange, Basse=vert)

#### Feuille 2 : Statistiques
**KPIs automatiques** (formules Excel) :
- Total User Stories
- US par statut (TerminÃ©, En cours, Ã€ faire)
- Points totaux et complÃ©tÃ©s
- Taux de complÃ©tion (%)
- RÃ©partition par prioritÃ©

#### Feuille 3 : Architecture
**RÃ©sumÃ© technique** :
- Sources : JSON + CSV
- Kafka : 2 topics (Profils, Factures)
- Spark : 1 Master + 2 Workers
- Transformations : T1, T2, T3
- Stockage : PostgreSQL (3 tables)
- BI : 3 dashboards Power BI
- ML : 2 modÃ¨les (PrÃ©diction + DÃ©tection)

---

## ğŸ” ARCHITECTURE DÃ‰TAILLÃ‰E

### ğŸ“¥ Sources de DonnÃ©es
- **Fichiers JSON** : Profils freelances
  ```json
  {nom: "Dupont", compÃ©tences: ["Python"], tarif_jour: 450â‚¬}
  ```
- **Fichiers CSV** : Factures
  ```
  freelance, montant, date
  Dupont, 4500â‚¬, Oct-2025
  ```

### ğŸš€ Kafka - 2 Topics
1. **Topic: Profils**
    - ReÃ§oit les nouveaux freelances
    - 2 partitions
    - RÃ©plication factor = 2

2. **Topic: Factures**
    - ReÃ§oit les paiements
    - 2 partitions
    - RÃ©plication factor = 2

### âš¡ Spark - Architecture DistribuÃ©e

**NÅ“ud MaÃ®tre** :
- Coordonne le travail
- Distribue les tÃ¢ches
- Interroge les workers : *"Tu as les donnÃ©es du freelance #245 ?"*

**Worker 1** :
- Traite freelances ID 1-500
- Partition 0

**Worker 2** :
- Traite freelances ID 501-1000
- Partition 1

### ğŸ’¾ 3 Transformations Spark SQL

**T1 : Nettoyage**
- Supprime doublons
- Valide les donnÃ©es

**T2 : Calculs Financiers**
- CA par freelance
- Revenus mensuels

**T3 : AgrÃ©gations**
- Top compÃ©tences demandÃ©es
- Taux d'occupation

### ğŸ—„ï¸ PostgreSQL (PGsql)

**Base : freelances_db**

**3 Tables** :
1. **Freelances** : Profils et compÃ©tences
2. **Factures** : Historique paiements
3. **Indicateurs** : KPIs et statistiques

### ğŸ“Š Power BI - 3 Dashboards

**1. Dashboard Financier**
- Top 10 freelances par CA
- Ã‰volution revenus mensuels

**2. Dashboard Ressources**
- CompÃ©tences disponibles
- Taux d'occupation : 78%

**3. Suivi Temps RÃ©el**
- Missions en cours
- Nouvelles factures

---

## ğŸ¯ CONCEPTS BIG DATA DÃ‰MONTRÃ‰S

### 1ï¸âƒ£ Distribution des DonnÃ©es
- **Kafka** : 2 topics avec 2 partitions chacun
- **Spark** : 2 workers traitent en parallÃ¨le
- **RÃ©sultat** : Traitement 2x plus rapide

### 2ï¸âƒ£ LocalitÃ© des DonnÃ©es
**ScÃ©nario** :
- MaÃ®tre : *"Worker 1, tu as les donnÃ©es de Dupont (#245) ?"*
- Worker 1 : *"Oui, en mÃ©moire, je te les renvoie"*
- **Avantage** : Ã‰vite les transferts rÃ©seau

### 3ï¸âƒ£ ScalabilitÃ© Horizontale
- Besoin de plus de puissance ?
- Ajoutez des workers : 2 â†’ 4 â†’ 8
- Performance augmente linÃ©airement

### 4ï¸âƒ£ Temps RÃ©el avec Streaming
- Kafka ingÃ¨re les donnÃ©es instantanÃ©ment
- Spark Streaming traite en continu
- Power BI affiche en temps rÃ©el (30s refresh)

---

## ğŸ› ï¸ STACK TECHNIQUE

| Composant | Technologie | Version | RÃ´le |
|-----------|------------|---------|------|
| Sources | JSON + CSV | - | DonnÃ©es brutes |
| Streaming | Apache Kafka | 3.x | 2 topics (Profils, Factures) |
| Traitement | Apache Spark | 3.5 | 1 Master + 2 Workers |
| SQL | Spark SQL | 3.5 | 3 Transformations (T1, T2, T3) |
| Stockage | PostgreSQL | 15 | Data Warehouse (PGsql) |
| BI | Power BI | Desktop | 3 Dashboards |
| ML | Spark MLlib | 3.5 | 2 ModÃ¨les prÃ©dictifs |
| CI/CD | GitHub Actions | - | DÃ©ploiement |
| Cloud | AWS/Azure | - | Infrastructure |

---

## ğŸ“Š KPIS PROJET

| KPI | Cible | Mesure |
|-----|-------|--------|
| **CA Mensuel** | 150kâ‚¬ | Dashboard Financier |
| **Taux Occupation** | 78% | Dashboard Ressources |
| **Top 10 CA** | 60% du total | Dashboard Financier |
| **Nouvelles Factures/jour** | 20+ | Suivi Temps RÃ©el |
| **PrÃ©diction CA MAPE** | < 15% | ModÃ¨le ML |
| **DÃ©tection Anomalies** | > 85% | ModÃ¨le ML |

---

## ğŸ“ POINTS CLÃ‰S POUR LA SOUTENANCE

### Architecture Technique âœ…
- **2 Topics Kafka** sÃ©parent Profils et Factures
- **2 Workers Spark** traitent ID 1-500 et 501-1000
- **3 Transformations** : Nettoyage â†’ Calculs â†’ AgrÃ©gations
- **3 Dashboards** : Financier, Ressources, Temps RÃ©el

### Big Data âœ…
- **Volume** : 1000 freelances, milliers de factures
- **VÃ©locitÃ©** : Kafka streaming temps rÃ©el
- **VariÃ©tÃ©** : JSON + CSV
- **Valeur** : KPIs mÃ©tier + ML prÃ©dictif

### Gestion Projet âœ…
- **Agile** : 7 sprints, 14 semaines
- **125 points** de complexitÃ©
- **14 User Stories** rÃ©parties en 7 Epics
- **Excel de suivi** avec liens Git/Backlog

### DÃ©monstration âœ…
1. Montrer le **pipeline Mermaid** (flux complet)
2. Expliquer la **distribution** (Worker 1 vs Worker 2)
3. PrÃ©senter les **3 dashboards Power BI**
4. DÃ©montrer la **localitÃ©** (interrogation workers)

---

## ğŸ“ FICHIERS LIVRÃ‰S

```
/mnt/user-data/outputs/
â”œâ”€â”€ pipeline-simple-clair.mermaid          # Pipeline complet
â”œâ”€â”€ diagramme-composants-v2.mermaid       # Architecture logique
â”œâ”€â”€ diagramme-deploiement-v2.mermaid      # Infrastructure physique
â”œâ”€â”€ indicateurs-bi-ml-v2.md               # KPIs + ML dÃ©taillÃ©s
â”œâ”€â”€ backlog-teams-v2.md                   # 14 User Stories
â”œâ”€â”€ suivi_git_backlog_v2.xlsx             # Excel de suivi
â””â”€â”€ recapitulatif-final.md                # Ce document
```

---

## ğŸš€ PROCHAINES Ã‰TAPES

1. âœ… **Validation** : Revue avec le tuteur
2. â³ **PrÃ©sentation** : Slides PowerPoint
3. â³ **DÃ©mo** : Prototype avec donnÃ©es test
4. â³ **Rapport** : Document technique complet
5. â³ **Soutenance** : PrÃ©sentation + Q&A

---

## ğŸ’¡ STRUCTURE PRÃ‰SENTATION (15-20 min)

**1. Contexte (2 min)**
- Plateforme de 1000 freelances
- ProblÃ¨me : Volume de donnÃ©es + besoin temps rÃ©el

**2. Architecture (8 min)**
- PrÃ©senter le pipeline complet
- Expliquer les 2 topics Kafka
- DÃ©tailler la distribution sur 2 workers
- Montrer les 3 transformations SQL

**3. Dashboards & KPIs (5 min)**
- Dashboard Financier : Top 10 + Ã‰volution
- Dashboard Ressources : CompÃ©tences + 78%
- Suivi Temps RÃ©el : Missions + Factures

**4. Big Data (3 min)**
- Distribution : 2x plus rapide
- LocalitÃ© : Ã‰viter transferts rÃ©seau
- ScalabilitÃ© : 2 â†’ 4 â†’ 8 workers
- Temps rÃ©el : Kafka + Spark Streaming

**5. Gestion Projet (2 min)**
- 7 sprints, 14 semaines
- 125 points de complexitÃ©
- Excel de suivi Git-Backlog

---

## â“ QUESTIONS PROBABLES DU JURY

**Techniques** :
- *"Pourquoi 2 topics au lieu d'un seul ?"*
  â†’ SÃ©paration des concerns, scalabilitÃ© indÃ©pendante

- *"Comment gÃ©rer la panne d'un worker ?"*
  â†’ Spark rÃ©assigne automatiquement les tÃ¢ches

- *"Pourquoi PostgreSQL et pas MongoDB ?"*
  â†’ Besoin de transactions ACID et requÃªtes SQL complexes

**MÃ©tier** :
- *"Quel ROI pour l'entreprise ?"*
  â†’ Automatisation, insights temps rÃ©el, prÃ©dictions CA

- *"Combien de temps pour dÃ©ployer ?"*
  â†’ 14 semaines (7 sprints de 2 semaines)

**Projet** :
- *"Quelles difficultÃ©s rencontrÃ©es ?"*
  â†’ Synchronisation Kafka-Spark, optimisation requÃªtes SQL

- *"Si c'Ã©tait Ã  refaire ?"*
  â†’ Commencer plus tÃ´t les tests d'intÃ©gration

---

## âœ… CHECKLIST FINALE

- âœ… Pipeline FreelanceFlow validÃ©
- âœ… Diagramme composants (2 topics, 3 transformations)
- âœ… Diagramme dÃ©ploiement (infrastructure cloud)
- âœ… Indicateurs BI (3 dashboards dÃ©taillÃ©s)
- âœ… Backlog Teams (14 US, 7 sprints)
- âœ… Excel Git-Backlog (3 feuilles complÃ¨tes)
- âœ… RÃ©capitulatif final (ce document)

---

**ğŸ“ Tous les livrables sont prÃªts pour votre soutenance !**

**Bonne chance ! ğŸš€**

---

**DerniÃ¨re mise Ã  jour** : 20/11/2025 - Version Finale  
**Projet** : FreelanceFlow - Architecture Big Data  
**Ã‰tudiant** : [Votre Nom]  
**Ã‰cole** : [Ã‰cole d'IngÃ©nieur]
